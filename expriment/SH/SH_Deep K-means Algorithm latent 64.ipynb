{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep K-Means Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is available.\n"
     ]
    }
   ],
   "source": [
    "# CPU/GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "num_clusters = 2 # k-mean에서는 num cluster를 hyperparameter로 정의\n",
    "latent_size = 64 # latent vector size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df) -> pd.DataFrame:\n",
    "    numeric_cols = [\n",
    "        'xmeas_1', 'xmeas_10', 'xmeas_11', 'xmeas_12', 'xmeas_13', 'xmeas_14',\n",
    "        'xmeas_15', 'xmeas_16', 'xmeas_17', 'xmeas_18', 'xmeas_19', 'xmeas_2',\n",
    "        'xmeas_20', 'xmeas_21', 'xmeas_22', 'xmeas_23', 'xmeas_24', 'xmeas_25',\n",
    "        'xmeas_26', 'xmeas_27', 'xmeas_28', 'xmeas_29', 'xmeas_3', 'xmeas_30',\n",
    "        'xmeas_31', 'xmeas_32', 'xmeas_33', 'xmeas_34', 'xmeas_35', 'xmeas_36',\n",
    "        'xmeas_37', 'xmeas_38', 'xmeas_39', 'xmeas_4', 'xmeas_40', 'xmeas_41',\n",
    "        'xmeas_5', 'xmeas_6', 'xmeas_7', 'xmeas_8', 'xmeas_9', 'xmv_1',\n",
    "        'xmv_10', 'xmv_11', 'xmv_2', 'xmv_3', 'xmv_4', 'xmv_5', 'xmv_6',\n",
    "        'xmv_7', 'xmv_8', 'xmv_9'\n",
    "    ]\n",
    "    return df[numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = process_data(train_data)\n",
    "X_test = process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_features(df):\n",
    "    # 새로운 feature를 저장할 딕셔너리\n",
    "    new_features = {}\n",
    "    \n",
    "    # xmeas_1부터 xmeas_8까지 반복\n",
    "    for i in range(1, 9):\n",
    "        # xmv_i - xmeas_* 계산하여 새로운 feature 생성\n",
    "        for j in range(1, 42):\n",
    "            new_feature_name = f'{i}_{j}'\n",
    "            new_features[new_feature_name] = df[f'xmv_{i}'] - df[f'xmeas_{j}']\n",
    "    # 딕셔너리를 데이터프레임으로 변환하여 반환\n",
    "    return pd.DataFrame(new_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = create_new_features(X_train)\n",
    "new_test = create_new_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.concat([train_data, new_train], axis=1)\n",
    "new_test = pd.concat([X_test, new_test], axis=1)\n",
    "\n",
    "# # 'simple'과 'simulationRun' 열 삭제\n",
    "# new_test = new_test.drop(columns=['simple', 'simulationRun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 simulationRun을 기준으로 분할하는 함수 정의\n",
    "def split_dataset_by_simulation(data):\n",
    "    unique_simulation_runs = data['simulationRun'].unique()\n",
    "    train_simulation_runs = unique_simulation_runs[:475]  # 처음 400개를 학습에 사용\n",
    "    val_simulation_runs = unique_simulation_runs[475:]  # 나머지를 검증에 사용\n",
    "    \n",
    "    train_data = data[data['simulationRun'].isin(train_simulation_runs)].drop(columns=['simulationRun','sample','faultNumber'])\n",
    "    val_data = data[data['simulationRun'].isin(val_simulation_runs)].drop(columns=['simulationRun','sample','faultNumber'])\n",
    "    \n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_val = split_dataset_by_simulation(new_train)\n",
    "\n",
    "# 데이터 스케일러 인스턴스 생성(데이터 표준화)\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# 학습 데이터셋에 대해 fit과 transform 수행: train 기준 정보 계산 및 데이터 변환\n",
    "X_train_scaled = scaler.fit_transform(X_train) \n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# PyTorch Tensor로 변환 \n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled) \n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled)\n",
    "\n",
    "# DataLoader 설정 \n",
    "train_dataset = TensorDataset(X_train_tensor, X_train_tensor)  # 입력과 타겟이 같음\n",
    "val_dataset = TensorDataset(X_val_tensor, X_val_tensor)  # 입력과 타겟이 같음\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터셋\n",
    "# 테스트 데이터셋에 대해서는 transform만 수행: 학습 데이터셋의 기준 정보를 사용하여 데이터 변환\n",
    "X_test_scaled = scaler.fit_transform(new_test)  \n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([500, 380])\n",
      "Target shape: torch.Size([500, 380])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 형식 확인 \n",
    "for data in train_loader:\n",
    "    inputs = data[0]  # 첫 번째 요소가 입력 데이터\n",
    "    targets = data[1]  # 두 번째 요소가 타겟 데이터\n",
    "    print(\"Input shape:\", inputs.shape)\n",
    "    print(\"Target shape:\", targets.shape)\n",
    "    # 여기에 데이터 형식에 대한 추가 확인 또는 시각화 코드 추가 가능\n",
    "    break  # 첫 번째 배치만 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 정의 (flatten, deflatten, encoder, decoder, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        k = 16\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(380, 256), \n",
    "            nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            nn.Linear(256, 128), \n",
    "            nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            nn.Linear(128, latent_size), \n",
    "            nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            # nn.Linear(64, latent_size), \n",
    "            # nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            # nn.Linear(32, latent_size), # 중간 차원 32에서 중간 차원 16로 압축\n",
    "            # nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            # nn.Linear(16, latent_size), # 중간 차원 16에서 특징 차원 8으로 더 압축\n",
    "            # nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "        )\n",
    "\n",
    "    def forward(self, x):       \n",
    "        return self.encoder(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        k = 16\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.Linear(latent_size, 16), # 특징 차원 8에서 중간 차원 16로 확장\n",
    "            # nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            # nn.Linear(latent_size, 32), # 중간 차원 16에서 중간 차원 32로 확장\n",
    "            # nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            # nn.Linear(latent_size, 64),\n",
    "            # nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            nn.Linear(latent_size, 128),\n",
    "            nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(), # 활성화 함수 ReLU 사용\n",
    "            nn.Linear(256, 380),\n",
    "            nn.Sigmoid() # 출력을 0과 1 사이로 조정\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):       \n",
    "        return self.decoder(x)\n",
    "        \n",
    "class Kmeans(nn.Module): \n",
    "    def __init__(self, num_clusters, latent_size):\n",
    "        super(Kmeans, self).__init__()\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.num_clusters = num_clusters\n",
    "        self.centroids = nn.Parameter(torch.rand((self.num_clusters, latent_size)).to(device))\n",
    "    \n",
    "    def argminl2distance(self, a, b): # L2 distance   \n",
    "        return torch.argmin(torch.sum((a-b)**2,dim=1),dim=0)\n",
    "    \n",
    "    # def argmin_manhattan_distance(self, a, b): # Manhattan Distance\n",
    "    #     return torch.argmin(torch.sum(torch.abs(a - b), dim=1), dim=0)\n",
    "\n",
    "    # def argmin_euclidean_distance(self, a, b): # Euclidean Distance\n",
    "    #     return torch.argmin(torch.sqrt(torch.sum((a - b)**2, dim=1)), dim=0)\n",
    "\n",
    "    # def argmin_chebyshev_distance(self, a, b): # Chebyshev Distance\n",
    "    #     return torch.argmin(torch.max(torch.abs(a - b), dim=1).values, dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_assign = []\n",
    "        for m in range(x.size(0)):\n",
    "            h = x[m].expand(self.num_clusters,-1)\n",
    "            assign = self.argminl2distance(h, self.centroids)\n",
    "            y_assign.append(assign.item())\n",
    "        \n",
    "        return y_assign, self.centroids[y_assign]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. clustering accuracy func justice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_acc(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true, dtype=np.int64)  # numpy 배열로 변환\n",
    "    y_pred = np.array(y_pred)  # 수정되지 않음\n",
    "\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    ind = linear_assignment(w.max() - w)\n",
    "    \n",
    "    return sum([w[i, j] for i, j in zip(ind[0], ind[1])]) * 1.0 / y_pred.size\n",
    "         \n",
    "def evaluation(testloader, encoder, kmeans, device):\n",
    "    predictions = []\n",
    "    actual = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            latent_var = encoder(inputs)\n",
    "            y_pred, _ = kmeans(latent_var)  # 클러스터링 결과\n",
    "\n",
    "            predictions += y_pred\n",
    "            actual += labels.tolist()\n",
    "\n",
    "    return cluster_acc(actual, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. loss and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(latent_size).to(device)\n",
    "decoder = Decoder(latent_size).to(device)\n",
    "kmeans = Kmeans(num_clusters, latent_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion1 = torch.nn.MSELoss()\n",
    "criterion2 = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(list(encoder.parameters()) + \n",
    "                              list(decoder.parameters()) +\n",
    "                              list(kmeans.parameters()), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "# ReduceLROnPlateau는 손실이 더 이상 개선되지 않을 때 학습률을 감소시키는 방법을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "T1 = 50\n",
    "T2 = 200\n",
    "lam = 1e-3\n",
    "ls = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Train loss: 0.7148, Val Accuracy: 1.000\n",
      "[1] Train loss: 0.6863, Val Accuracy: 1.000\n",
      "[2] Train loss: 0.6817, Val Accuracy: 1.000\n",
      "[3] Train loss: 0.6788, Val Accuracy: 1.000\n",
      "[4] Train loss: 0.6760, Val Accuracy: 1.000\n",
      "[5] Train loss: 0.6736, Val Accuracy: 1.000\n",
      "[6] Train loss: 0.6723, Val Accuracy: 1.000\n",
      "[7] Train loss: 0.6708, Val Accuracy: 1.000\n",
      "[8] Train loss: 0.6700, Val Accuracy: 1.000\n",
      "[9] Train loss: 0.6693, Val Accuracy: 1.000\n",
      "[10] Train loss: 0.6688, Val Accuracy: 1.000\n",
      "[11] Train loss: 0.6683, Val Accuracy: 1.000\n",
      "[12] Train loss: 0.6679, Val Accuracy: 1.000\n",
      "[13] Train loss: 0.6678, Val Accuracy: 1.000\n",
      "[14] Train loss: 0.6669, Val Accuracy: 1.000\n",
      "[15] Train loss: 0.6660, Val Accuracy: 1.000\n",
      "[16] Train loss: 0.6655, Val Accuracy: 1.000\n",
      "[17] Train loss: 0.6654, Val Accuracy: 1.000\n",
      "[18] Train loss: 0.6652, Val Accuracy: 1.000\n",
      "[19] Train loss: 0.6650, Val Accuracy: 1.000\n",
      "[20] Train loss: 0.6649, Val Accuracy: 1.000\n",
      "[21] Train loss: 0.6647, Val Accuracy: 1.000\n",
      "[22] Train loss: 0.6646, Val Accuracy: 1.000\n",
      "[23] Train loss: 0.6646, Val Accuracy: 1.000\n",
      "[24] Train loss: 0.6646, Val Accuracy: 1.000\n",
      "[25] Train loss: 0.6645, Val Accuracy: 1.000\n",
      "[26] Train loss: 0.6644, Val Accuracy: 1.000\n",
      "[27] Train loss: 0.6644, Val Accuracy: 1.000\n",
      "[28] Train loss: 0.6643, Val Accuracy: 1.000\n",
      "[29] Train loss: 0.6644, Val Accuracy: 1.000\n",
      "[30] Train loss: 0.6643, Val Accuracy: 1.000\n",
      "[31] Train loss: 0.6643, Val Accuracy: 1.000\n",
      "[32] Train loss: 0.6643, Val Accuracy: 1.000\n",
      "[33] Train loss: 0.6643, Val Accuracy: 1.000\n",
      "[34] Train loss: 0.6643, Val Accuracy: 1.000\n",
      "[35] Train loss: 0.6642, Val Accuracy: 1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m latent_var \u001b[38;5;241m=\u001b[39m encoder(inputs)\n\u001b[0;32m---> 16\u001b[0m _, centroids \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_var\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m decoder(latent_var)\n\u001b[1;32m     19\u001b[0m l_rec \u001b[38;5;241m=\u001b[39m criterion1(inputs, outputs) \n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[25], line 61\u001b[0m, in \u001b[0;36mKmeans.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[1;32m     60\u001b[0m     h \u001b[38;5;241m=\u001b[39m x[m]\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_clusters,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     assign \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margminl2distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcentroids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     y_assign\u001b[38;5;241m.\u001b[39mappend(assign\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_assign, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids[y_assign]\n",
      "Cell \u001b[0;32mIn[25], line 55\u001b[0m, in \u001b[0;36mKmeans.argminl2distance\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margminl2distance\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b): \u001b[38;5;66;03m# L2 distance   \u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39margmin(torch\u001b[38;5;241m.\u001b[39msum(\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(300):\n",
    "    if (ep > T1) and (ep < T2):\n",
    "        alpha = lam*(ep - T1)/(T2 - T1) # 1/100, 2/100, .., 99/100\n",
    "    elif ep >= T2:    \n",
    "        alpha = lam\n",
    "    else:\n",
    "        alpha = lam/(T2 - T1)\n",
    "        \n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.to(device)  # 데이터를 디바이스로 이동\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        latent_var = encoder(inputs)\n",
    "        _, centroids = kmeans(latent_var.detach())\n",
    "        outputs = decoder(latent_var)\n",
    "        \n",
    "        l_rec = criterion1(inputs, outputs) \n",
    "        l_clt = criterion2(latent_var, centroids) \n",
    "        loss = l_rec + alpha*l_clt\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "  \n",
    "    avg_loss = running_loss / len(train_loader)        \n",
    "    \n",
    "    if ep % 1 == 0:               \n",
    "        testacc = evaluation(val_loader, encoder, kmeans, device)\n",
    "        print('[%d] Train loss: %.4f, Val Accuracy: %.3f' %(ep, avg_loss, testacc))  \n",
    "        \n",
    "    if avg_loss < ls:\n",
    "        ls = avg_loss\n",
    "        torch.save(encoder.state_dict(),'./models/dkm5_en.pth')\n",
    "        torch.save(decoder.state_dict(),'./models/dkm5_de.pth')\n",
    "        torch.save(kmeans.state_dict(),'./models/dkm5_clt.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "actual = []\n",
    "latent_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:  # 테스트 데이터셋의 배치마다 반복\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        latent_var = encoder(inputs)  # 입력 데이터를 인코더에 통과시켜 잠재 변수를 추출\n",
    "        y_pred, _ = kmeans(latent_var)  # 클러스터링 결과\n",
    "        \n",
    "        predictions += y_pred  # 예측된 클러스터를 리스트에 추가\n",
    "        latent_features += latent_var.cpu().tolist()  # 잠재 변수를 리스트에 추가\n",
    "        actual += labels.tolist()  # 실제 레이블을 리스트에 추가\n",
    "\n",
    "print(cluster_acc(actual, predictions))  # 클러스터링 정확도 계산 및 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 평가 모드로 설정\n",
    "encoder.eval()\n",
    "kmeans.eval()\n",
    "\n",
    "# 테스트 데이터셋을 디바이스로 이동\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "\n",
    "# 테스트 데이터셋을 모델에 전달하여 추론\n",
    "with torch.no_grad():\n",
    "    latent_var_test = encoder(X_test_tensor)  # 테스트 데이터셋의 잠재 변수 추출\n",
    "    y_pred_test, _ = kmeans(latent_var_test)  # 클러스터링 결과\n",
    "\n",
    "# y_pred_test가 리스트 형식이므로 텐서로 변환\n",
    "y_pred_test = torch.tensor(y_pred_test)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "results = pd.DataFrame({'faultNumber': y_pred_test.cpu().numpy()})\n",
    "results.to_csv('deepkmeans_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faultNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>710400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.067572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.251010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         faultNumber\n",
       "count  710400.000000\n",
       "mean        0.067572\n",
       "std         0.251010\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulationRun\n",
      "0      333\n",
      "1      325\n",
      "2      349\n",
      "3      304\n",
      "4      309\n",
      "      ... \n",
      "735    330\n",
      "736    314\n",
      "737    839\n",
      "738    816\n",
      "739    356\n",
      "Length: 740, dtype: int64\n",
      "count    740.000000\n",
      "mean     423.258108\n",
      "std      181.811162\n",
      "min      278.000000\n",
      "25%      326.750000\n",
      "50%      340.000000\n",
      "75%      381.000000\n",
      "max      866.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.concat([test_data, results], axis=1)\n",
    "counts = merged_df[merged_df['faultNumber']==1].groupby('simulationRun').size()\n",
    "print(counts)\n",
    "print(counts.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "faultNumber\n",
      "0    533760\n",
      "1    176640\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "less_than_500 = counts[counts > 381].index.tolist()\n",
    "print(len(less_than_500))\n",
    "# less_than_500에 해당하는 simulationRun의 faultNumber를 1로, 나머지는 0으로 설정\n",
    "merged_df['faultNumber'] = merged_df['simulationRun'].apply(lambda x: 1 if x in less_than_500 else 0)\n",
    "merged_df['faultNumber'].to_csv(\"deepkmeans_1edit.csv\")\n",
    "print(merged_df['faultNumber'] .value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'reconstruction error distribution')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# reconstruction error 계산 \n",
    "reconstruction_errors = torch.mean((outputs - inputs) ** 2, axis=1).detach()  #MSE\n",
    "\n",
    "# reconstruction error 히스토그램 시각화 \n",
    "plt.hist(reconstruction_errors.numpy(), bins=50) \n",
    "plt.xlabel('reconstruction error') \n",
    "plt.ylabel('frequency') \n",
    "plt.title('reconstruction error distribution')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
